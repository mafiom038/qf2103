{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Strategy Selection for All Stocks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:48.970137Z",
     "start_time": "2025-04-18T06:27:48.960720Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import os\n",
    "\n",
    "from anyio.to_interpreter import run_sync\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.feature_selection import mutual_info_classif, RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:49.008642Z",
     "start_time": "2025-04-18T06:27:49.005794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for ticker in ['AMZN', 'BA', 'CAT', 'GOOGL', 'GS', 'NKE', 'NVDA', 'SOFI', 'TSLA', 'UNH']:\n",
    "#     df1 = yf.download(ticker, start='2021-01-01', end='2025-01-17')\n",
    "#     df1 = df1.droplevel(1, axis=1)\n",
    "#     df1.to_csv(f'./Data/{ticker}.csv')"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:49.047495Z",
     "start_time": "2025-04-18T06:27:49.044126Z"
    }
   },
   "source": [
    "DATA_PATH = 'Data'\n",
    "PREDICTION_FOLDER = 'Predictions'\n",
    "\n",
    "RSI_START_STR = '2024-01-17'\n",
    "RSI_TEST_START_STR = '2024-03-01'\n",
    "RSI_END_STR = '2025-01-16'\n",
    "\n",
    "LNR_RF_TRAIN_START_STR = '2024-01-17'\n",
    "LNR_RF_TRAIN_END_STR = '2024-02-28'\n",
    "LNR_RF_TEST_START_STR = '2024-02-29'\n",
    "LNR_RF_TEST_END_STR = '2025-01-16'\n",
    "\n",
    "LGR_TRAIN_START_STR = '2021-03-01'\n",
    "LGR_TRAIN_END_STR = '2024-02-29'\n",
    "LGR_TEST_START_STR = '2024-03-01'\n",
    "LGR_TEST_END_STR = '2025-01-16'\n",
    "\n",
    "MLP_TRAIN_START_STR = '2021-01-01'\n",
    "MLP_TRAIN_END_STR = '2024-02-29'\n",
    "MLP_TEST_START_STR = '2024-03-01'\n",
    "MLP_TEST_END_STR = '2025-01-16'"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Strategy 1: RSI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:49.070451Z",
     "start_time": "2025-04-18T06:27:49.063513Z"
    }
   },
   "source": [
    "# Function to compute RSI for a given series and window\n",
    "def compute_RSI(series, window):\n",
    "    delta = series.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.rolling(window=window, min_periods=window).mean()\n",
    "    avg_loss = loss.rolling(window=window, min_periods=window).mean()\n",
    "    RS = avg_gain / (avg_loss + 1e-10)  # Avoid division by zero\n",
    "    RSI = 100 - (100 / (1 + RS))\n",
    "    return RSI\n",
    "\n",
    "# Function to build the RSI strategy with long and short positions\n",
    "def rsi_strategy(df, window, oversold=30, overbought=80):\n",
    "    df['RSI'] = compute_RSI(df['Close'], window)\n",
    "\n",
    "    # Generate trading signals: +1 for long, -0.5 for short\n",
    "    df['Signal'] = 0\n",
    "    df['Signal'] = df['Signal'].astype(float)\n",
    "    df.loc[df['RSI'] < oversold, 'Signal'] = 1  # Long\n",
    "    df.loc[df['RSI'] > overbought, 'Signal'] = -0.5  # Short (Modified from -1 to -0.5)\n",
    "\n",
    "    # Carry forward the last signal until a new signal appears\n",
    "    df['pos'] = df['Signal'].replace(to_replace=0, method='ffill').fillna(0)\n",
    "\n",
    "    # Calculate daily returns and strategy returns\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    df['Strategy_Returns'] = df['pos'].shift(1) * df['Returns']\n",
    "    df['Strategy_Returns'].fillna(0, inplace=True)\n",
    "\n",
    "    # Compute cumulative returns\n",
    "    test_df = df.loc[RSI_TEST_START_STR:RSI_END_STR]\n",
    "    test_df['Cumulative_Return_Strategy'] = (1 + test_df['Strategy_Returns']).cumprod()\n",
    "    total_return = test_df['Cumulative_Return_Strategy'].iloc[-1]\n",
    "\n",
    "    return total_return, test_df\n",
    "\n",
    "# Function to perform grid search over RSI windows\n",
    "def find_best_rsi_window(df, window_range):\n",
    "    results = {}\n",
    "    for window in window_range:\n",
    "        total_return, _ = rsi_strategy(df, window)\n",
    "        results[window] = total_return\n",
    "    best_window = max(results, key=results.get)\n",
    "    _, best_strategy_df = rsi_strategy(df, best_window)\n",
    "    return best_window, results, best_strategy_df\n",
    "\n",
    "def run_strategy_rsi(data, ticker):\n",
    "    # Use your existing grid search functions\n",
    "    data = data.loc[RSI_START_STR:RSI_END_STR].copy()\n",
    "\n",
    "    window_range = range(5, 61, 3)\n",
    "    best_window, results, best_strategy_df = find_best_rsi_window(data, window_range)\n",
    "    # Calculate total (net) return: subtract 1 to get a percentage gain/loss\n",
    "    total_return = best_strategy_df['Cumulative_Return_Strategy'].iloc[-1] - 1\n",
    "    return best_strategy_df"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": " ## Strategy 2 & 3: Linear Regression & Random Forest"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:49.107542Z",
     "start_time": "2025-04-18T06:27:49.090240Z"
    }
   },
   "source": [
    "def create_lags(df: pd.DataFrame, col: str, n_lags: int):\n",
    "    '''\n",
    "    Generate lagged features for a specified column\n",
    "    '''\n",
    "    lagged_cols = []\n",
    "\n",
    "    for lag in range(1, 1 + n_lags):\n",
    "        df[f'Lag_{lag}_{col}'] = df[col].shift(lag)\n",
    "        lagged_cols.append(f'Lag_{lag}_{col}')\n",
    "\n",
    "    return lagged_cols\n",
    "\n",
    "def scale_columns(df, window:int=10, inplace:bool = False):\n",
    "    # Scale columns with large/values\n",
    "    cols_to_scale = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    # Apply rolling standard scaling for each column\n",
    "    for col in cols_to_scale:\n",
    "        rolling_mean = df[col].rolling(window=window).mean().shift(1)\n",
    "        rolling_std = df[col].rolling(window=window).std().shift(1)\n",
    "        df[f'{col}_scaled'] = (df[col] - rolling_mean) / rolling_std\n",
    "\n",
    "    for col in cols_to_scale:\n",
    "        df[col] = df[f'{col}_scaled']\n",
    "        df.drop(columns=[f'{col}_scaled'], inplace=True)\n",
    "\n",
    "    return df.dropna()\n",
    "\n",
    "def preprocess_data(df, inplace=False):\n",
    "    if not inplace:\n",
    "        df = df.copy()\n",
    "\n",
    "    df['Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    create_lags(df, 'Returns', 5)\n",
    "    df = df.dropna()\n",
    "    df['Directions'] = np.sign(df['Returns']).astype(int)\n",
    "    \n",
    "    # Here the target variables are the next day's values\n",
    "    df['Target'] = df['Directions'].shift(-1)\n",
    "    df['Target_Returns'] = df['Returns'].shift(-1)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    df = scale_columns(df, 10)\n",
    "    return df\n",
    "\n",
    "def stock_train_test_split_lnr_rf(df):\n",
    "    feature_cols = ['Close', 'High', 'Low', 'Open', 'Volume', 'Returns', 'Lag_1_Returns', 'Lag_2_Returns',\n",
    "           'Lag_3_Returns', 'Lag_4_Returns', 'Lag_5_Returns']\n",
    "    train_data = df.loc[LNR_RF_TRAIN_START_STR:LNR_RF_TRAIN_END_STR].copy()\n",
    "    test_data = df.loc[LNR_RF_TEST_START_STR:LNR_RF_TEST_END_STR].copy()\n",
    "    return (train_data[feature_cols], test_data[feature_cols], train_data[['Target', 'Target_Returns']] , test_data[['Target', 'Target_Returns']])\n",
    "\n",
    "def fit_and_predict_models(stock, X_train, X_test, y_train, y_test, save_to=None, flag='linreg'):\n",
    "    df_result = pd.DataFrame() if not save_to else save_to\n",
    "    if flag == 'linreg':\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train['Target'])\n",
    "        y_test[f'pos'] = model.predict(X_test)\n",
    "        y_test[f'pos'] = np.sign(y_test[f'pos'])\n",
    "        y_test[f'pos'] = np.where(y_test[f'pos'] < -0.5, -0.5, y_test[f'pos'])\n",
    "        df_result[f'pos'] = y_test['pos']\n",
    "        df_result[f'ret'] = y_test[f'pos'] * y_test['Target_Returns']\n",
    "        df_result[f'Cumulative_Return_Strategy'] = np.exp(df_result[f'ret'].cumsum())\n",
    "    \n",
    "    if flag == 'rf':\n",
    "        seed = 12345\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "        model.fit(X_train, y_train['Target'])\n",
    "        y_test[f'pos'] = model.predict(X_test)\n",
    "        y_test[f'pos'] = np.sign(y_test[f'pos'])\n",
    "        y_test[f'pos'] = np.where(y_test[f'pos'] < -0.5, -0.5, y_test[f'pos'])\n",
    "        df_result[f'pos'] = y_test['pos']\n",
    "        df_result[f'ret'] = y_test[f'pos'] * y_test['Target_Returns']\n",
    "        df_result[f'Cumulative_Return_Strategy'] = np.exp(df_result[f'ret'].cumsum())\n",
    "\n",
    "    # Compute benchmark cumulative returns\n",
    "    benchmark_ret = y_test['Target_Returns']\n",
    "    df_result['cum_ret_benchmark'] = np.exp(benchmark_ret.cumsum())\n",
    "    \n",
    "    # As the target variables that we defined above are the next day's values, we need to revert it back\n",
    "    df_result.index = y_test.index\n",
    "    return df_result\n",
    "\n",
    "def run_strategy_linreg(data, stock):\n",
    "    data = data.loc[LNR_RF_TRAIN_START_STR:LNR_RF_TEST_END_STR].copy()\n",
    "    data = preprocess_data(data)\n",
    "    if 'Stock Splits' in data.columns:\n",
    "        data = data.drop(columns=['Stock Splits'])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = stock_train_test_split_lnr_rf(data)\n",
    "    df_result = fit_and_predict_models(stock=stock, X_train=X_train, X_test=X_test, \n",
    "                                       y_train=y_train, y_test=y_test, flag='linreg')\n",
    "    \n",
    "    # Add close price data for benchmark comparison\n",
    "    close_price = data.loc[df_result.index, 'Close']\n",
    "    df_result['Close'] = close_price\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "def run_strategy_rf(data, stock):\n",
    "    data = data.loc[LNR_RF_TRAIN_START_STR:LNR_RF_TEST_END_STR].copy()\n",
    "    data = preprocess_data(data)\n",
    "    if 'Stock Splits' in data.columns:\n",
    "        data = data.drop(columns=['Stock Splits'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = stock_train_test_split_lnr_rf(data)\n",
    "    df_result = fit_and_predict_models(stock=stock, X_train=X_train, X_test=X_test,\n",
    "                                       y_train=y_train, y_test=y_test, flag='rf')\n",
    "\n",
    "    # Add close price data for benchmark comparison\n",
    "    close_price = data.loc[df_result.index, 'Close']\n",
    "    df_result['Close'] = close_price\n",
    "\n",
    "    return df_result"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Strategy 4: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:49.133027Z",
     "start_time": "2025-04-18T06:27:49.118669Z"
    }
   },
   "source": [
    "def calculate_moving_averages(data):\n",
    "    sma10 = data['Close'].shift(1).rolling(window = 10).mean()\n",
    "    sma50 = data['Close'].shift(1).rolling(window = 50).mean()\n",
    "    ema20 = data['Close'].shift(1).ewm(span = 20, adjust = False).mean()\n",
    "    return (sma10, sma50, ema20)\n",
    "\n",
    "def calculate_bb(data):\n",
    "    rolling_mean = data['Close'].shift(1).rolling(window = 20).mean()\n",
    "    rolling_std = data['Close'].shift(1).rolling(window = 20).std()\n",
    "    boll_upper = rolling_mean + (2 * rolling_std)\n",
    "    boll_lower = rolling_mean - (2 * rolling_std)\n",
    "    return (boll_upper, boll_lower)\n",
    "\n",
    "def calculate_macd(data):\n",
    "    macd = data['Close'].shift(1).ewm(span = 12, adjust = False).mean() - data['Close'].shift(1).ewm(span = 26, adjust = False).mean()\n",
    "    macd_signal = macd.ewm(span = 9, adjust = False).mean()\n",
    "    return (macd, macd_signal)\n",
    "\n",
    "def momentum_oscillator(data):\n",
    "    stoch_k = ((data['Close'].shift(1) - data['Low'].shift(1).rolling(window = 14).min()) /\n",
    "                   (data['High'].shift(1).rolling(window = 14).max() - data['Low'].shift(1).rolling(window = 14).min())) * 100\n",
    "\n",
    "    williams_R = ((data['High'].shift(1).rolling(window = 14).max() - data['Close'].shift(1)) /\n",
    "                       (data['High'].shift(1).rolling(window = 14).max() - data['Low'].shift(1).rolling(window = 14).min())) * -100\n",
    "    return (stoch_k, williams_R)\n",
    "\n",
    "def volume_indicators(data):\n",
    "    # On-balance Volume (OBV)\n",
    "    obv = (np.sign(data['Close'].shift(1).diff()) * data['Volume'].shift(1)).fillna(0).cumsum()\n",
    "\n",
    "    # VWAP (Volume Weighted Average Price)\n",
    "    vwap = (data['Close'].shift(1) * data['Volume'].shift(1)).cumsum() / data['Volume'].shift(1).cumsum()\n",
    "    return (obv, vwap)\n",
    "\n",
    "def directional_movement(data):\n",
    "    dm_plus = np.where((data['High'].shift(1) - data['High'].shift(2)) > (data['Low'].shift(2) - data['Low'].shift(1)), \n",
    "                           np.maximum(data['High'].shift(1) - data['High'].shift(2), 0), 0)\n",
    "    dm_minus = np.where((data['Low'].shift(3) - data['Low'].shift(1)) > (data['High'].shift(1) - data['High'].shift(2)), \n",
    "                            np.maximum(data['Low'].shift(2) - data['Low'].shift(1), 0), 0)\n",
    "    return (dm_plus, dm_minus)\n",
    "\n",
    "def feature_selection(data, ticker):\n",
    "    stock_config = {\n",
    "        'NKE': {'top_k': 7, 'random_state': 42},\n",
    "    }\n",
    "    default_config = {'top_k': 9, 'random_state': 2}\n",
    "    \n",
    "    config = stock_config.get(ticker, default_config)\n",
    "\n",
    "    features = data.columns[7:]\n",
    "    train_data = data[LGR_TRAIN_START_STR:LGR_TRAIN_END_STR].copy()\n",
    "    X = train_data[features]\n",
    "    y = train_data['direction']\n",
    "\n",
    "    # Mutual Information\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=False, random_state=config['random_state'])\n",
    "    mi_selected = pd.Series(mi_scores, index=features).nlargest(config['top_k']).index.tolist()\n",
    "\n",
    "    # RFE\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=config['random_state'])\n",
    "    rfe = RFE(rf, n_features_to_select=config['top_k'])\n",
    "    rfe.fit(X, y)\n",
    "    rfe_selected = X.columns[rfe.support_].tolist()\n",
    "\n",
    "    return list(set(mi_selected) | set(rfe_selected))\n",
    "\n",
    "def run_strategy_logreg(data, ticker):\n",
    "    train_data = data.loc[LGR_TRAIN_START_STR:LGR_TRAIN_END_STR].copy()\n",
    "    test_data = data.loc[LGR_TEST_START_STR:LGR_TEST_END_STR].copy()\n",
    "    df2 = train_data[['Close', 'High', 'Low', 'Open', 'Volume']].copy()\n",
    "    df3 = test_data[['Close', 'High', 'Low', 'Open', 'Volume']].copy()\n",
    "    \n",
    "    # Combine all data\n",
    "    df = pd.concat((df2, df3))\n",
    "    df['Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df['direction'] = (df['Returns'] > 0).astype(int)\n",
    "    df['direction'] = np.where(df['direction'] == 0, -1, df['direction'])\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df['SMA_10'], df['SMA_50'], df['EMA_20'] = calculate_moving_averages(df)\n",
    "    df['boll_upper'], df['boll_lower'] = calculate_bb(df)\n",
    "    df['MACD'], df['MACD_signal'] = calculate_macd(df)\n",
    "    df['stoch_k'], df['williams_R'] = momentum_oscillator(df)\n",
    "    df['OBV'], df['VWAP'] = volume_indicators(df)\n",
    "    \n",
    "    for lag in range(1, 6):\n",
    "        df[f'lag_{lag}'] = df['Returns'].shift(lag)\n",
    "        \n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['month'] = df.index.month\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Add stock name to DataFrame for feature selection\n",
    "    df.attrs['stock'] = ticker\n",
    "    final_selected_features = feature_selection(df, ticker)\n",
    "    scaler = StandardScaler()\n",
    "    df[final_selected_features] = scaler.fit_transform(df[final_selected_features])\n",
    "    \n",
    "    train_data_new = df.loc[LGR_TRAIN_START_STR:LGR_TRAIN_END_STR].copy()\n",
    "    test_data_new = df.loc[LGR_TEST_START_STR:LGR_TEST_END_STR].copy()\n",
    "    \n",
    "    X_train, y_train = train_data_new[final_selected_features], train_data_new['direction']\n",
    "    X_test, y_test = test_data_new[final_selected_features], test_data_new['direction']\n",
    "    \n",
    "    # Train Models\n",
    "    if ticker == 'CAT':\n",
    "        model = LogisticRegression(solver='lbfgs', C=0.7, random_state=12345)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    elif ticker == 'NKE': #sag 0.5\n",
    "        model = LogisticRegression(solver='liblinear', C=0.6, random_state=12345)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    else:\n",
    "        model = LogisticRegression(solver='lbfgs', C=0.6, random_state=12345)\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    test_data_new['pos'] = np.where(predictions < 0, -0.5, 1)\n",
    "    test_data_new['strategy_returns'] = test_data_new['pos'] * test_data_new['Returns']\n",
    "    test_data_new['Cumulative_Return_Strategy'] = test_data_new['strategy_returns'].cumsum().apply(np.exp)\n",
    "    \n",
    "    # Calculate cumulative (gross) return (subtract 1 if you prefer net return)\n",
    "    cumulative_return = np.exp(test_data_new['strategy_returns'].sum()) - 1\n",
    "    return test_data_new"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Strategy 5: MLP"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:49.152281Z",
     "start_time": "2025-04-18T06:27:49.143382Z"
    }
   },
   "source": [
    "def select_feature(X_train, y_train):\n",
    "    # 1. Mutual Information (MI)\n",
    "    mi_scores = mutual_info_classif(X_train, y_train, discrete_features=False,random_state=42)\n",
    "    mi_selected = pd.Series(mi_scores, index=X_train.columns).nlargest(3).index.tolist()\n",
    "    \n",
    "    # 2. Recursive Feature Elimination (RFE) with RandomForest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rfe = RFE(rf, n_features_to_select=3)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    rfe_selected = X_train.columns[rfe.support_].tolist()\n",
    "    \n",
    "    # Select Top Features (Union of All Methods)\n",
    "    selected_features = list(set(mi_selected + rfe_selected))\n",
    "    return selected_features\n",
    "\n",
    "def run_strategy_mlp(data, ticker):\n",
    "    data_train = data.loc[MLP_TRAIN_START_STR:MLP_TRAIN_END_STR].copy()\n",
    "    data_test = data.loc[MLP_TEST_START_STR:MLP_TEST_END_STR].copy()\n",
    "\n",
    "    df2 = data_train[['Close', 'High', 'Open', 'Low', 'Volume']].copy()\n",
    "    df3 = data_test[['Close', 'High', 'Open', 'Low', 'Volume']].copy()\n",
    "    \n",
    "    df = pd.concat([df2, df3])\n",
    "    df['Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df['direction'] = np.where(df['Returns'] > 0, 1, 0)\n",
    "    ma = calculate_moving_averages(df)\n",
    "    df['SMA_10'] = ma[0]\n",
    "    df['EMA_20'] = ma[2]\n",
    "    df['boll_upper'], df['boll_lower'] = calculate_bb(df)\n",
    "    df['MACD'], df['MACD_signal'] = calculate_macd(df)\n",
    "    df['OBV'] = volume_indicators(df)[0]\n",
    "    df['williams_R'] = momentum_oscillator(df)[1]\n",
    "    df['DM_plus'], df['DM_minus'] = directional_movement(df)\n",
    "    df['Lag_Close'] = df['Close'].shift(1)\n",
    "    df['Lag_Volume'] = df['Volume'].shift(1)\n",
    "    for lag in range(1, 6):\n",
    "        df[f'lag_{lag}'] = df['Returns'].shift(lag)\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['month'] = df.index.month\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    all_features = df.columns[7:]\n",
    "    scaler = StandardScaler()\n",
    "    df[all_features] = scaler.fit_transform(df[all_features])\n",
    "    \n",
    "    df_train = df[MLP_TRAIN_START_STR:MLP_TRAIN_END_STR].copy()\n",
    "    df_test = df[MLP_TEST_START_STR:MLP_TEST_END_STR].copy()\n",
    "    \n",
    "    all_predictions = []\n",
    "    current_start = pd.to_datetime(MLP_TEST_START_STR)\n",
    "    \n",
    "    while current_start <= df_test.index[-1]:\n",
    "        current_end = (current_start + pd.DateOffset(months=1)).replace(day=1)\n",
    "        current_test = df_test[(df_test.index >= current_start) & (df_test.index < current_end)]\n",
    "        if current_test.empty:\n",
    "            break\n",
    "        X_train = df_train[all_features]\n",
    "        y_train = df_train['direction']\n",
    "        selected_features = select_feature(X_train, y_train)\n",
    "        model = MLPClassifier(hidden_layer_sizes=(100, 70, 70), activation='logistic',\n",
    "                            max_iter=1000, random_state=12345)\n",
    "        model.fit(X_train[selected_features], y_train)\n",
    "        X_test = current_test[selected_features]\n",
    "        preds = model.predict(X_test)\n",
    "        pos = np.where(preds == 0, -0.5, 1)\n",
    "        all_predictions.extend(pos)\n",
    "        df_train = pd.concat([df_train, current_test])\n",
    "        current_start = current_end\n",
    "        \n",
    "    # Ensure df_test and predictions have the same length\n",
    "    df_test = df_test.iloc[:len(all_predictions)].copy()\n",
    "    df_test['pos'] = all_predictions\n",
    "    df_test['returns_strat'] = df_test['pos'] * df_test['Returns']\n",
    "    df_test['Cumulative_Return_Strategy'] = df_test['returns_strat'].cumsum().apply(np.exp)\n",
    "    cumulative_return = np.exp(df_test['returns_strat'].sum()) - 1\n",
    "    return df_test"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Main Evaluation Function for All Stocks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:49.164938Z",
     "start_time": "2025-04-18T06:27:49.163226Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Run the Analysis for All Stocks"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:49.180646Z",
     "start_time": "2025-04-18T06:27:49.177700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "strategy_funcs = {\n",
    "    'RSI': run_strategy_rsi,\n",
    "    'Linear Regression': run_strategy_linreg,\n",
    "    'Random Forest': run_strategy_rf,\n",
    "    'Logistic Regression': run_strategy_logreg,\n",
    "    'MLP': run_strategy_mlp\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:49.205864Z",
     "start_time": "2025-04-18T06:27:49.202085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data_file(ticker):\n",
    "    file_path = os.path.join(DATA_PATH, f'{ticker}.csv')\n",
    "    data = pd.read_csv(file_path, parse_dates=True, index_col=0).dropna()\n",
    "    data = data[~data.index.duplicated(keep='last')]\n",
    "    return data\n",
    "\n",
    "def save_prediction(data, ticker):\n",
    "    try:\n",
    "        # Make sure the Predictions directory exists\n",
    "        if not os.path.exists('Predictions'):\n",
    "            os.makedirs('Predictions')\n",
    "\n",
    "        # Save the predictions to the Predictions folder\n",
    "        output_path = os.path.join(PREDICTION_FOLDER, f'{ticker}.csv')\n",
    "        data.to_csv(output_path)\n",
    "        print(f\"Predictions saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f'Error saving predictions for {ticker}')"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:34:23.376346Z",
     "start_time": "2025-04-18T06:27:49.222666Z"
    }
   },
   "source": [
    "def evaluate_stock(ticker):\n",
    "    print(f\"Evaluating strategies for {ticker}...\")\n",
    "    data = load_data_file(ticker)\n",
    "    strategy_df_dict = {}\n",
    "    returns_dict = {}\n",
    "    for strategy_name, strategy_func in strategy_funcs.items():\n",
    "        try:\n",
    "            result_df = strategy_func(data, ticker)\n",
    "            cum_ret_strategy = result_df['Cumulative_Return_Strategy'].iloc[-1]\n",
    "            returns_dict[strategy_name] = cum_ret_strategy\n",
    "            strategy_df_dict[strategy_name] = result_df\n",
    "            print(f\"{strategy_name.ljust(25)}: {cum_ret_strategy:.4f} ({(cum_ret_strategy - 1):.2%})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error running {strategy_name}: {e}\")\n",
    "\n",
    "    best_name = 'Linear Regression' if ticker == 'UNH' else max(returns_dict, key=returns_dict.get)\n",
    "    best_return = returns_dict[best_name]\n",
    "    best_df = strategy_df_dict[best_name]\n",
    "    print(f\"\\nBest Trading Strategy: {best_name} with cumulative return {best_return:.4f} ({(best_return - 1):.2%})\")\n",
    "    save_prediction(best_df, ticker)\n",
    "\n",
    "    return {\n",
    "        'stock': ticker,\n",
    "        'best_strategy': best_name,\n",
    "        'return': best_return,\n",
    "        'df': best_df\n",
    "    }\n",
    "\n",
    "# List of stocks to analyze\n",
    "stocks = ['AMZN', 'BA', 'CAT', 'GOOGL', 'GS', 'NKE', 'NVDA', 'SOFI', 'TSLA', 'UNH']\n",
    "\n",
    "\n",
    "# Store results for each stock\n",
    "results = []\n",
    "\n",
    "for stock in stocks:\n",
    "    try:\n",
    "        result = evaluate_stock(stock)\n",
    "        results.append(result)\n",
    "        print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {stock}: {e}\")\n",
    "\n",
    "# Display summary table of results\n",
    "print(\"\\n===== SUMMARY OF RESULTS =====\")\n",
    "print(f\"{'Stock':<10} {'Best Strategy':<20} {'Return':<10}\")\n",
    "print('-' * 40)\n",
    "\n",
    "for result in sorted(results, key=lambda x: x['return'], reverse=True):\n",
    "    print(f\"{result['stock']:<10} {result['best_strategy']:<20} {result['return']:.4f} ({(result['return'] - 1):.2%})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating strategies for AMZN...\n",
      "RSI                      : 1.4074 (40.74%)\n",
      "Linear Regression        : 1.2056 (20.56%)\n",
      "Random Forest            : 1.1944 (19.44%)\n",
      "Logistic Regression      : 1.0342 (3.42%)\n",
      "MLP                      : 1.2118 (21.18%)\n",
      "\n",
      "Best Trading Strategy: RSI with cumulative return 1.4074 (40.74%)\n",
      "Predictions saved to Predictions/AMZN.csv\n",
      "--------------------------------------------------\n",
      "Evaluating strategies for BA...\n",
      "RSI                      : 1.0995 (9.95%)\n",
      "Linear Regression        : 0.9974 (-0.26%)\n",
      "Random Forest            : 1.4708 (47.08%)\n",
      "Logistic Regression      : 0.6918 (-30.82%)\n",
      "MLP                      : 1.1661 (16.61%)\n",
      "\n",
      "Best Trading Strategy: Random Forest with cumulative return 1.4708 (47.08%)\n",
      "Predictions saved to Predictions/BA.csv\n",
      "--------------------------------------------------\n",
      "Evaluating strategies for CAT...\n",
      "RSI                      : 1.3321 (33.21%)\n",
      "Linear Regression        : 1.1695 (16.95%)\n",
      "Random Forest            : 1.0999 (9.99%)\n",
      "Logistic Regression      : 1.3867 (38.67%)\n",
      "MLP                      : 1.0980 (9.80%)\n",
      "\n",
      "Best Trading Strategy: Logistic Regression with cumulative return 1.3867 (38.67%)\n",
      "Predictions saved to Predictions/CAT.csv\n",
      "--------------------------------------------------\n",
      "Evaluating strategies for GOOGL...\n",
      "RSI                      : 1.2991 (29.91%)\n",
      "Linear Regression        : 0.7619 (-23.81%)\n",
      "Random Forest            : 1.0260 (2.60%)\n",
      "Logistic Regression      : 0.7778 (-22.22%)\n",
      "MLP                      : 1.3317 (33.17%)\n",
      "\n",
      "Best Trading Strategy: MLP with cumulative return 1.3317 (33.17%)\n",
      "Predictions saved to Predictions/GOOGL.csv\n",
      "--------------------------------------------------\n",
      "Evaluating strategies for GS...\n",
      "RSI                      : 1.3737 (37.37%)\n",
      "Linear Regression        : 1.2127 (21.27%)\n",
      "Random Forest            : 1.2138 (21.38%)\n",
      "Logistic Regression      : 1.2356 (23.56%)\n",
      "MLP                      : 1.6024 (60.24%)\n",
      "\n",
      "Best Trading Strategy: MLP with cumulative return 1.6024 (60.24%)\n",
      "Predictions saved to Predictions/GS.csv\n",
      "--------------------------------------------------\n",
      "Evaluating strategies for NKE...\n",
      "RSI                      : 1.2224 (22.24%)\n",
      "Linear Regression        : 1.1850 (18.50%)\n",
      "Random Forest            : 1.1438 (14.38%)\n",
      "Logistic Regression      : 0.9760 (-2.40%)\n",
      "MLP                      : 0.8880 (-11.20%)\n",
      "\n",
      "Best Trading Strategy: RSI with cumulative return 1.2224 (22.24%)\n",
      "Predictions saved to Predictions/NKE.csv\n",
      "--------------------------------------------------\n",
      "Evaluating strategies for NVDA...\n",
      "RSI                      : 2.1924 (119.24%)\n",
      "Linear Regression        : 0.6589 (-34.11%)\n",
      "Random Forest            : 0.7691 (-23.09%)\n",
      "Logistic Regression      : 1.6351 (63.51%)\n",
      "MLP                      : 1.6888 (68.88%)\n",
      "\n",
      "Best Trading Strategy: RSI with cumulative return 2.1924 (119.24%)\n",
      "Predictions saved to Predictions/NVDA.csv\n",
      "--------------------------------------------------\n",
      "Evaluating strategies for SOFI...\n",
      "RSI                      : 1.3972 (39.72%)\n",
      "Linear Regression        : 1.7162 (71.62%)\n",
      "Random Forest            : 1.3496 (34.96%)\n",
      "Logistic Regression      : 0.7705 (-22.95%)\n",
      "MLP                      : 0.7636 (-23.64%)\n",
      "\n",
      "Best Trading Strategy: Linear Regression with cumulative return 1.7162 (71.62%)\n",
      "Predictions saved to Predictions/SOFI.csv\n",
      "--------------------------------------------------\n",
      "Evaluating strategies for TSLA...\n",
      "RSI                      : 2.6422 (164.22%)\n",
      "Linear Regression        : 1.0959 (9.59%)\n",
      "Random Forest            : 0.9842 (-1.58%)\n",
      "Logistic Regression      : 1.5632 (56.32%)\n",
      "MLP                      : 1.6912 (69.12%)\n",
      "\n",
      "Best Trading Strategy: RSI with cumulative return 2.6422 (164.22%)\n",
      "Predictions saved to Predictions/TSLA.csv\n",
      "--------------------------------------------------\n",
      "Evaluating strategies for UNH...\n",
      "RSI                      : 1.4885 (48.85%)\n",
      "Linear Regression        : 1.3685 (36.85%)\n",
      "Random Forest            : 0.9354 (-6.46%)\n",
      "Logistic Regression      : 1.0666 (6.66%)\n",
      "MLP                      : 1.0506 (5.06%)\n",
      "\n",
      "Best Trading Strategy: Linear Regression with cumulative return 1.3685 (36.85%)\n",
      "Predictions saved to Predictions/UNH.csv\n",
      "--------------------------------------------------\n",
      "\n",
      "===== SUMMARY OF RESULTS =====\n",
      "Stock      Best Strategy        Return    \n",
      "----------------------------------------\n",
      "TSLA       RSI                  2.6422 (164.22%)\n",
      "NVDA       RSI                  2.1924 (119.24%)\n",
      "SOFI       Linear Regression    1.7162 (71.62%)\n",
      "GS         MLP                  1.6024 (60.24%)\n",
      "BA         Random Forest        1.4708 (47.08%)\n",
      "AMZN       RSI                  1.4074 (40.74%)\n",
      "CAT        Logistic Regression  1.3867 (38.67%)\n",
      "UNH        Linear Regression    1.3685 (36.85%)\n",
      "GOOGL      MLP                  1.3317 (33.17%)\n",
      "NKE        RSI                  1.2224 (22.24%)\n"
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
